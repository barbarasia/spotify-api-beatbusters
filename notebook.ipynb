{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Barbara/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from time import sleep\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import pickle\n",
    "from IPython.display import IFrame, display\n",
    "import numpy as np\n",
    "\n",
    "CLIENT_ID = os.getenv(\"spotipy_id\")\n",
    "CLIENT_SECRET = os.getenv(\"spotipy_secret\")\n",
    "\n",
    "#Initialize SpotiPy with user credentials\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(client_id=CLIENT_ID,\n",
    "                                                           client_secret=CLIENT_SECRET))\n",
    "df = pd.read_csv('/Users/Barbara/Desktop/Ironhack/Labs/Week_6/spotipy-api/tracks_clustered_df.csv')\n",
    "df_tf = pd.read_csv('/Users/Barbara/Desktop/Ironhack/Labs/Week_6/spotipy-api/tracks_and_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"320\"\n",
       "            height=\"80\"\n",
       "            src=\"https://open.spotify.com/embed/track/63OQupATfueTdZMWTxW03A?utm_source=generator?frameborder=0&allowtransparency=true&allow=encrypted-media\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x113577bb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the user's favorite song and artist\n",
    "fav_song = input(\"What's your favorite song? \")\n",
    "fav_song_artist = input(\"Who's the artist? \")\n",
    "\n",
    "# Search for the song on Spotify\n",
    "results = sp.search(q=\"track:\"+fav_song+\" artist:\"+fav_song_artist, limit=1)\n",
    "\n",
    "# Check if a track was found\n",
    "if results['tracks']['items']:\n",
    "    # Extract the track details\n",
    "    track = results['tracks']['items'][0]\n",
    "    track_name = track['name']\n",
    "    track_artist = track['artists'][0]['name']\n",
    "    track_id = track['id']\n",
    "\n",
    "    # Display the Spotify embed before asking for confirmation\n",
    "    display(IFrame(src=f\"https://open.spotify.com/embed/track/{track_id}?utm_source=generator\",\n",
    "                   width=\"320\",\n",
    "                   height=\"80\",\n",
    "                   frameborder=\"0\",\n",
    "                   allowtransparency=\"true\",\n",
    "                   allow=\"encrypted-media\"))\n",
    "\n",
    "    # # Ask for confirmation\n",
    "    # response = input('Is it the song? (Y/N) ')\n",
    "\n",
    "    # if response.upper() == 'Y':\n",
    "    #     # If confirmed, proceed with the recommendation logic\n",
    "    #     # Assuming `tracks_clustered_df` is your DataFrame with track clusters\n",
    "    #     # and `new_song_scaled_features` is the scaled features of the new song\n",
    "    #     # prediction = km_100.predict(new_song_scaled_features)\n",
    "        \n",
    "    #     # # Get a recommendation from the same cluster\n",
    "    #     # recommendation2 = tracks_clustered_df[tracks_clustered_df['cluster_km100'] == prediction[0]].sample(1)\n",
    "    #     # recommended_track_id = recommendation2['track_id'].iloc[0]\n",
    "\n",
    "    #     # # Display the recommended song\n",
    "    #     # display(IFrame(src=f\"https://open.spotify.com/embed/track/{recommended_track_id}?utm_source=generator\",\n",
    "    #     #                width=\"320\",\n",
    "    #     #                height=\"80\",\n",
    "    #     #                frameborder=\"0\",\n",
    "    #     #                allowtransparency=\"true\",\n",
    "    #     #                allow=\"encrypted-media\"))\n",
    "    # else:\n",
    "    #     print('Are you sure the song exists? Try again.')\n",
    "else:\n",
    "    print('No matching song found. Please check the details and try again.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the song ID '63OQupATfueTdZMWTxW03A' in the dataset? True\n"
     ]
    }
   ],
   "source": [
    "def check_song_in_dataset(track_id, df):\n",
    "    return track_id in df['track_id'].values\n",
    "\n",
    "# Example usage\n",
    "track_id_to_check = track_id\n",
    "is_in_dataset = check_song_in_dataset(track_id_to_check, df)\n",
    "print(f\"Is the song ID '{track_id_to_check}' in the dataset? {is_in_dataset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"320\"\n",
       "            height=\"80\"\n",
       "            src=\"https://open.spotify.com/embed/track/3uZyx7GfVWJh2Aum6xS6my?utm_source=generator?frameborder=0&allowtransparency=true&allow=encrypted-media\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1749d72b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### with training the model\n",
    "\n",
    "list_of_audio_features_fav=[]\n",
    "list_of_audio_features_fav.extend(sp.audio_features(track_id))\n",
    "list_of_audio_features_fav = list_of_audio_features_fav [0]\n",
    "\n",
    "danceability = []\n",
    "energy = []\n",
    "key = []\n",
    "loudness = []\n",
    "mode = []\n",
    "speechiness = []\n",
    "acousticness = []\n",
    "instrumentalness = []\n",
    "liveness = []\n",
    "valence = []\n",
    "tempo = []\n",
    "duration_ms = []\n",
    "time_signature = []\n",
    "track_href = []\n",
    "\n",
    "\n",
    "danceability.append(list_of_audio_features_fav['danceability'])\n",
    "energy.append(list_of_audio_features_fav['energy'])\n",
    "key.append(list_of_audio_features_fav.get('key', -1))\n",
    "loudness.append(list_of_audio_features_fav['loudness'])\n",
    "mode.append(list_of_audio_features_fav['mode'])\n",
    "speechiness.append(list_of_audio_features_fav['speechiness'])\n",
    "acousticness.append(list_of_audio_features_fav['acousticness'])\n",
    "instrumentalness.append(list_of_audio_features_fav['instrumentalness'])\n",
    "liveness.append(list_of_audio_features_fav['liveness'])\n",
    "valence.append(list_of_audio_features_fav['valence'])\n",
    "tempo.append(list_of_audio_features_fav['tempo'])\n",
    "duration_ms.append(list_of_audio_features_fav['duration_ms'])\n",
    "time_signature.append(list_of_audio_features_fav['time_signature'])\n",
    "track_href.append(list_of_audio_features_fav['track_href'])\n",
    "\n",
    "audio_features_dict = {\n",
    "    'danceability':danceability,\n",
    "    'energy':energy,\n",
    "    'key':key,\n",
    "    'loudness':loudness,\n",
    "    'mode':mode,\n",
    "    'speechiness':speechiness,\n",
    "    'acousticness':acousticness,\n",
    "    'instrumentalness':instrumentalness,\n",
    "    'liveness':liveness,\n",
    "    'valence':valence,\n",
    "    'tempo':tempo,\n",
    "    'duration_ms':duration_ms,\n",
    "    'time_signature':time_signature,\n",
    "    'track_href':track_href\n",
    "    }\n",
    "\n",
    "audio_features_df = pd.DataFrame(audio_features_dict)\n",
    "\n",
    "artist_ids = []\n",
    "artist_names = []\n",
    "track_ids = []\n",
    "track_href_1 = []\n",
    "track_names = []\n",
    "album_release_dates = []\n",
    "album_release_date_precisions = []\n",
    "popularity = []\n",
    "is_explicit = []\n",
    "durations_ms = []\n",
    "\n",
    "artist_ids.append(results['tracks']['items'][0]['artists'][0]['id'])\n",
    "artist_names.append(results['tracks']['items'][0]['artists'][0]['name'])\n",
    "track_ids.append(results['tracks']['items'][0]['id'])\n",
    "track_href_1.append(results['tracks']['items'][0]['href'])\n",
    "track_names.append(results['tracks']['items'][0]['name'])\n",
    "popularity.append(results['tracks']['items'][0]['popularity'])\n",
    "is_explicit.append(results['tracks']['items'][0]['explicit'])\n",
    "durations_ms.append(results['tracks']['items'][0]['duration_ms'])\n",
    "album_release_dates.append(results['tracks']['items'][0]['album']['release_date'])\n",
    "album_release_date_precisions.append(results['tracks']['items'][0]['album']['release_date_precision'])\n",
    "\n",
    "\n",
    "tracks_df_fav = pd.DataFrame(\n",
    "{'artist_id':artist_ids\n",
    ",'artist_name':artist_names\n",
    ", 'track_id':track_ids\n",
    ", 'track_name':track_names\n",
    ", 'album_release_date':album_release_dates\n",
    ", 'album_release_date_precision':album_release_date_precisions\n",
    ", 'is_explicit': is_explicit\n",
    ", 'durations_ms':durations_ms\n",
    ", 'popularity':popularity\n",
    ", 'track_href_1':track_href_1})\n",
    "\n",
    "merged_fav = pd.merge(tracks_df_fav, audio_features_df, left_on='track_href_1', right_on='track_href')\n",
    "merged_fav.columns\n",
    "merged_fav = merged_fav.drop(columns=['track_href_1'])\n",
    "\n",
    "new_df = pd.concat([df_tf, merged_fav], axis=0, ignore_index=True)\n",
    "\n",
    "audio_features_model_on = ['is_explicit','popularity', 'danceability', 'energy', 'key',\n",
    "       'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness',\n",
    "       'liveness', 'valence', 'tempo', 'time_signature']\n",
    "features_df = new_df[audio_features_model_on]\n",
    "\n",
    "km100 = KMeans(100)\n",
    "scaler = MinMaxScaler()\n",
    "scaled_features = scaler.fit_transform(features_df)\n",
    "km100.fit(scaled_features)\n",
    "\n",
    "tracks_clustered_df = new_df.copy()\n",
    "tracks_clustered_df['cluster_km100'] = km100.labels_\n",
    "\n",
    "# Assuming `merged_fav` contains the new track data\n",
    "new_track_id = merged_fav['track_id'].iloc[-1]  # Get the track_id of the newly added track\n",
    "\n",
    "# Get the cluster number for the new track\n",
    "cluster_number = tracks_clustered_df[tracks_clustered_df['track_id'] == new_track_id]['cluster_km100'].iloc[0]\n",
    "\n",
    "\n",
    "#put the path to the cluster of the new song\n",
    "recommendation = tracks_clustered_df[tracks_clustered_df['cluster_km100'] == cluster_number].sample(1)\n",
    "\n",
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(src=\"https://open.spotify.com/embed/track/\"+ recommendation['track_id'].iloc[0] +\"?utm_source=generator\",\n",
    "\n",
    "       width=\"320\",\n",
    "       height=\"80\",\n",
    "       frameborder=\"0\",\n",
    "       allowtransparency=\"true\",\n",
    "       allow=\"encrypted-media\",\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_fav['key'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Barbara/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator MinMaxScaler from version 1.4.1.post1 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/Barbara/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator KMeans from version 1.4.1.post1 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"320\"\n",
       "            height=\"80\"\n",
       "            src=\"https://open.spotify.com/embed/track/3NZJlJemX3mzjf56MqC5ML?utm_source=generator?frameborder=0&allowtransparency=true&allow=encrypted-media\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1749cb340>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### with Pickling\n",
    "\n",
    "\n",
    "audio_features_model_on = ['is_explicit','popularity', 'danceability', 'energy', 'key',\n",
    "       'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness',\n",
    "       'liveness', 'valence', 'tempo', 'time_signature']\n",
    "features_df_fav = merged_fav[audio_features_model_on]\n",
    "\n",
    "\n",
    "# Load the scaler and the KMeans model\n",
    "with open('scaler.pickle', 'rb') as handle:\n",
    "    scaler = pickle.load(handle)\n",
    "with open('model_km100.pickle', 'rb') as handle:\n",
    "    km_100 = pickle.load(handle)\n",
    "\n",
    "# Assuming `new_song_features` is your new data\n",
    "new_song_scaled_features = scaler.transform(features_df_fav)\n",
    "\n",
    "# Use the loaded KMeans model to make predictions\n",
    "prediction = km_100.predict(new_song_scaled_features[[-1]])[0]\n",
    "\n",
    "\n",
    "recommendation2 = df[df['cluster_km100'] == prediction].sample(1)\n",
    "recommendation2['track_id'].iloc[0]\n",
    "\n",
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(src=\"https://open.spotify.com/embed/track/\"+ recommendation2['track_id'].iloc[0] +\"?utm_source=generator\",\n",
    "       #src=\"spotify:track:3rTIcUMMP2Ez33DfjJlb9e:autoplay:true\",\n",
    "       width=\"320\",\n",
    "       height=\"80\",\n",
    "       frameborder=\"0\",\n",
    "       allowtransparency=\"true\",\n",
    "       allow=\"encrypted-media\",\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster at Level 1: 0\n",
      "Cluster at Level 2: 0\n",
      "Cluster at Level 3: 1\n",
      "Cluster at Level 4: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"320\"\n",
       "            height=\"80\"\n",
       "            src=\"https://open.spotify.com/embed/track/4WfV1CNg91SBp8oG0VY0VB?utm_source=generator?frameborder=0&allowtransparency=true&allow=encrypted-media\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x315b69520>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "with open('/Users/Barbara/Desktop/Ironhack/Labs/Week_6/spotipy-api/final.pkl', 'rb') as handle:\n",
    "    data_loaded = pickle.load(handle)\n",
    "\n",
    "# Extract objects from the loaded data\n",
    "scaler_L1 = data_loaded['scaler_L1']\n",
    "scaler_L2 = data_loaded['scaler_L2']\n",
    "scaler_L3 = data_loaded['scaler_L3']\n",
    "scaler_L4 = data_loaded['scaler_L4']\n",
    "kmeans_L1 = data_loaded['kmeans_L1']\n",
    "kmeans_L2_models = data_loaded['kmeans_L2_models']\n",
    "kmeans_L3_models = data_loaded['kmeans_L3_models']\n",
    "kmeans_L4_models = data_loaded['kmeans_L4_models']\n",
    "features_df = data_loaded['features_df']\n",
    "\n",
    "# Select features for each level\n",
    "features_L1 = ['valence', 'energy', 'acousticness']\n",
    "features_L2 = ['danceability', 'tempo', 'liveness']\n",
    "features_L3 = ['instrumentalness', 'speechiness', 'loudness']\n",
    "features_L4 = ['key', 'mode']\n",
    "\n",
    "# Scale the input features\n",
    "input_features_scaled_L1 = scaler_L1.transform(audio_features_df[features_L1])\n",
    "input_features_scaled_L2 = scaler_L2.transform(audio_features_df[features_L2])\n",
    "input_features_scaled_L3 = scaler_L3.transform(audio_features_df[features_L3])\n",
    "input_features_scaled_L4 = scaler_L4.transform(audio_features_df[features_L4])\n",
    "\n",
    "# Predict cluster at Level 1\n",
    "cluster_L1 = kmeans_L1.predict(input_features_scaled_L1)[0]\n",
    "\n",
    "# Predict cluster at Level 2\n",
    "kmeans_L2 = kmeans_L2_models[cluster_L1]\n",
    "cluster_L2 = kmeans_L2.predict(input_features_scaled_L2)[0]\n",
    "\n",
    "# Predict cluster at Level 3\n",
    "kmeans_L3 = kmeans_L3_models[cluster_L2]\n",
    "cluster_L3 = kmeans_L3.predict(input_features_scaled_L3)[0]\n",
    "\n",
    "# Predict cluster at Level 4\n",
    "kmeans_L4 = kmeans_L4_models[cluster_L3]\n",
    "cluster_L4 = kmeans_L4.predict(input_features_scaled_L4)[0]\n",
    "\n",
    "print(f\"Cluster at Level 1: {cluster_L1}\")\n",
    "print(f\"Cluster at Level 2: {cluster_L2}\")\n",
    "print(f\"Cluster at Level 3: {cluster_L3}\")\n",
    "print(f\"Cluster at Level 4: {cluster_L4}\")\n",
    "\n",
    "\n",
    "features_df=df_tf\n",
    "\n",
    "# Grouping the audio features into cluster levels\n",
    "features_L1 = ['valence', 'energy', 'acousticness']\n",
    "features_L2 = ['danceability', 'tempo', 'liveness']\n",
    "features_L3 = ['instrumentalness', 'speechiness', 'loudness']\n",
    "features_L4 = ['key', 'mode']\n",
    "\n",
    "# Create separate scalers for each level\n",
    "scaler_L1 = StandardScaler()\n",
    "scaler_L2 = StandardScaler()\n",
    "scaler_L3 = StandardScaler()\n",
    "scaler_L4 = StandardScaler()\n",
    "\n",
    "def perform_clustering(data, n_clusters):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    clusters = kmeans.fit_predict(data)\n",
    "    return clusters, kmeans\n",
    "\n",
    "# Level 1 clustering\n",
    "level_L1_scaled = scaler_L1.fit_transform(features_df[features_L1])\n",
    "clusters_L1, kmeans_L1 = perform_clustering(level_L1_scaled, n_clusters=10)\n",
    "\n",
    "features_df['cluster_L1'] = clusters_L1\n",
    "\n",
    "# Initialize the final clusters list\n",
    "final_clusters = np.zeros(features_df.shape[0])\n",
    "\n",
    "# Secondary clustering (Level 2)\n",
    "cluster_counter = 0\n",
    "kmeans_L2_models = {}\n",
    "for cluster_L1_label in np.unique(clusters_L1):\n",
    "    level_2_data = features_df[features_df['cluster_L1'] == cluster_L1_label][features_L2]\n",
    "    level_2_scaled = scaler_L2.fit_transform(level_2_data)\n",
    "    clusters_L2, kmeans_L2 = perform_clustering(level_2_scaled, n_clusters=5)\n",
    "    \n",
    "    features_df.loc[features_df['cluster_L1'] == cluster_L1_label, 'cluster_L2'] = clusters_L2 + cluster_counter * 5\n",
    "    kmeans_L2_models[cluster_L1_label] = kmeans_L2\n",
    "    cluster_counter += 1\n",
    "\n",
    "# Clustering for Level 3\n",
    "cluster_counter = 0\n",
    "kmeans_L3_models = {}\n",
    "for cluster_L2_label in np.unique(features_df['cluster_L2']):\n",
    "    level_3_data = features_df[features_df['cluster_L2'] == cluster_L2_label][features_L3]\n",
    "    level_3_scaled = scaler_L3.fit_transform(level_3_data)\n",
    "    clusters_L3, kmeans_L3 = perform_clustering(level_3_scaled, n_clusters=2)\n",
    "    \n",
    "    features_df.loc[features_df['cluster_L2'] == cluster_L2_label, 'cluster_L3'] = clusters_L3 + cluster_counter * 2\n",
    "    kmeans_L3_models[cluster_L2_label] = kmeans_L3\n",
    "    cluster_counter += 1\n",
    "\n",
    "# Clustering for Level 4\n",
    "cluster_counter = 0\n",
    "kmeans_L4_models = {}\n",
    "for cluster_L3_label in np.unique(features_df['cluster_L3']):\n",
    "    level_4_data = features_df[features_df['cluster_L3'] == cluster_L3_label][features_L4]\n",
    "    level_4_scaled = scaler_L4.fit_transform(level_4_data)\n",
    "    clusters_L4, kmeans_L4 = perform_clustering(level_4_scaled, n_clusters=2)\n",
    "    \n",
    "    features_df.loc[features_df['cluster_L3'] == cluster_L3_label, 'cluster_L4'] = clusters_L4 + cluster_counter\n",
    "    kmeans_L4_models[cluster_L3_label] = kmeans_L4\n",
    "    cluster_counter += 1\n",
    "\n",
    "input_clusters = {\n",
    "    'L1': cluster_L1,\n",
    "    'L2': cluster_L2,\n",
    "    'L3': cluster_L3,\n",
    "    'L4': cluster_L4\n",
    "}\n",
    "    # Assuming input_clusters are already computed as cluster_L1, cluster_L2, cluster_L3, cluster_L4\n",
    "\n",
    "# Function to calculate weighted common clusters\n",
    "def calculate_weighted_common_clusters(row):\n",
    "    weighted_score = 0\n",
    "    if row['cluster_L4'] == input_clusters['L4']:\n",
    "        weighted_score += 4  # Weight for level 4\n",
    "    if row['cluster_L3'] == input_clusters['L3']:\n",
    "        weighted_score += 3  # Weight for level 3\n",
    "    if row['cluster_L2'] == input_clusters['L2']:\n",
    "        weighted_score += 2  # Weight for level 2\n",
    "    if row['cluster_L1'] == input_clusters['L1']:\n",
    "        weighted_score += 1  # Weight for level 1\n",
    "    return weighted_score\n",
    "\n",
    "# Calculate weighted common clusters for each song\n",
    "features_df['weighted_common_clusters'] = features_df.apply(calculate_weighted_common_clusters, axis=1)\n",
    "\n",
    "# Find song with the maximum weighted common clusters\n",
    "top_recommendation = features_df.loc[features_df['weighted_common_clusters'].idxmax()]\n",
    "\n",
    "# Optionally, filter out input song itself from recommendations\n",
    "\n",
    "\n",
    "# Now `top_recommendation` is the song from `features_df` that has the most clusters in common with the input song,\n",
    "# with bias towards higher levels of clustering\n",
    "top_recommendation\n",
    "\n",
    "\n",
    "IFrame(src=\"https://open.spotify.com/embed/track/\"+ top_recommendation['track_id'] +\"?utm_source=generator\",\n",
    "       #src=\"spotify:track:3rTIcUMMP2Ez33DfjJlb9e:autoplay:true\",\n",
    "       width=\"320\",\n",
    "       height=\"80\",\n",
    "       frameborder=\"0\",\n",
    "       allowtransparency=\"true\",\n",
    "       allow=\"encrypted-media\",\n",
    "      )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster at Level 1: 1\n",
      "Cluster at Level 2: 1\n",
      "Cluster at Level 3: 0\n",
      "Cluster at Level 4: 0\n",
      "Unique Clusters at Level 1: [0 1 2 3 4 5 6 7 8 9]\n",
      "Unique Clusters at Level 2: [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
      " 18. 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30. 31. 32. 33. 34. 35.\n",
      " 36. 37. 38. 39. 40. 41. 42. 43. 44. 45. 46. 47. 48. 49.]\n",
      "Unique Clusters at Level 3: [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
      " 18. 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30. 31. 32. 33. 34. 35.\n",
      " 36. 37. 38. 39. 40. 41. 42. 43. 44. 45. 46. 47. 48. 49. 50. 51. 52. 53.\n",
      " 54. 55. 56. 57. 58. 59. 60. 61. 62. 63. 64. 65. 66. 67. 68. 69. 70. 71.\n",
      " 72. 73. 74. 75. 76. 77. 78. 79. 80. 81. 82. 83. 84. 85. 86. 87. 88. 89.\n",
      " 90. 91. 92. 93. 94. 95. 96. 97. 98. 99.]\n",
      "Unique Clusters at Level 4: [  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.\n",
      "  14.  15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.\n",
      "  28.  29.  30.  31.  32.  33.  34.  35.  36.  37.  38.  39.  40.  41.\n",
      "  42.  43.  44.  45.  46.  47.  48.  49.  50.  51.  52.  53.  54.  55.\n",
      "  56.  57.  58.  59.  60.  61.  62.  63.  64.  65.  66.  67.  68.  69.\n",
      "  70.  71.  72.  73.  74.  75.  76.  77.  78.  79.  80.  81.  82.  83.\n",
      "  84.  85.  86.  87.  88.  89.  90.  91.  92.  93.  94.  95.  96.  97.\n",
      "  98.  99. 100.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import pickle\n",
    "\n",
    "# Load data\n",
    "with open('/Users/Barbara/Desktop/Ironhack/Labs/Week_6/spotipy-api/final.pkl', 'rb') as handle:\n",
    "    data_loaded = pickle.load(handle)\n",
    "\n",
    "# Extract objects from the loaded data\n",
    "scaler_L1 = data_loaded['scaler_L1']\n",
    "scaler_L2 = data_loaded['scaler_L2']\n",
    "scaler_L3 = data_loaded['scaler_L3']\n",
    "scaler_L4 = data_loaded['scaler_L4']\n",
    "kmeans_L1 = data_loaded['kmeans_L1']\n",
    "kmeans_L2_models = data_loaded['kmeans_L2_models']\n",
    "kmeans_L3_models = data_loaded['kmeans_L3_models']\n",
    "kmeans_L4_models = data_loaded['kmeans_L4_models']\n",
    "features_df = data_loaded['features_df']\n",
    "\n",
    "# Define features for each level\n",
    "features_L1 = ['valence', 'energy', 'acousticness']\n",
    "features_L2 = ['danceability', 'tempo', 'liveness']\n",
    "features_L3 = ['instrumentalness', 'speechiness', 'loudness']\n",
    "features_L4 = ['key', 'mode']\n",
    "\n",
    "# Load and scale the input features\n",
    "input_features_scaled_L1 = scaler_L1.transform(features_df[features_L1])\n",
    "input_features_scaled_L2 = scaler_L2.transform(features_df[features_L2])\n",
    "input_features_scaled_L3 = scaler_L3.transform(features_df[features_L3])\n",
    "input_features_scaled_L4 = scaler_L4.transform(features_df[features_L4])\n",
    "\n",
    "# Predict clusters at each level\n",
    "cluster_L1 = kmeans_L1.predict(input_features_scaled_L1)[0]\n",
    "kmeans_L2 = kmeans_L2_models[cluster_L1]\n",
    "cluster_L2 = kmeans_L2.predict(input_features_scaled_L2)[0]\n",
    "kmeans_L3 = kmeans_L3_models[cluster_L2]\n",
    "cluster_L3 = kmeans_L3.predict(input_features_scaled_L3)[0]\n",
    "kmeans_L4 = kmeans_L4_models[cluster_L3]\n",
    "cluster_L4 = kmeans_L4.predict(input_features_scaled_L4)[0]\n",
    "\n",
    "print(f\"Cluster at Level 1: {cluster_L1}\")\n",
    "print(f\"Cluster at Level 2: {cluster_L2}\")\n",
    "print(f\"Cluster at Level 3: {cluster_L3}\")\n",
    "print(f\"Cluster at Level 4: {cluster_L4}\")\n",
    "\n",
    "# Verify clusters\n",
    "print(\"Unique Clusters at Level 1:\", np.unique(features_df['cluster_L1']))\n",
    "print(\"Unique Clusters at Level 2:\", np.unique(features_df['cluster_L2']))\n",
    "print(\"Unique Clusters at Level 3:\", np.unique(features_df['cluster_L3']))\n",
    "print(\"Unique Clusters at Level 4:\", np.unique(features_df['cluster_L4']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
